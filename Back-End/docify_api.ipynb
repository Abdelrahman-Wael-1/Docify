{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-26T06:27:13.691116Z",
     "iopub.status.busy": "2025-11-26T06:27:13.690587Z",
     "iopub.status.idle": "2025-11-26T06:27:13.938577Z",
     "shell.execute_reply": "2025-11-26T06:27:13.938017Z",
     "shell.execute_reply.started": "2025-11-26T06:27:13.691092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:27:13.939893Z",
     "iopub.status.busy": "2025-11-26T06:27:13.939604Z",
     "iopub.status.idle": "2025-11-26T06:28:37.486047Z",
     "shell.execute_reply": "2025-11-26T06:28:37.484916Z",
     "shell.execute_reply.started": "2025-11-26T06:27:13.939870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn pyngrok transformers==4.52.4 accelerate python-docx -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:28:37.487722Z",
     "iopub.status.busy": "2025-11-26T06:28:37.487416Z",
     "iopub.status.idle": "2025-11-26T06:28:44.862830Z",
     "shell.execute_reply": "2025-11-26T06:28:44.862053Z",
     "shell.execute_reply.started": "2025-11-26T06:28:37.487692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from fastapi import FastAPI, Request, HTTPException, UploadFile, File\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import FileResponse\n",
    "import uvicorn\n",
    "import threading\n",
    "import time\n",
    "import socket\n",
    "from pyngrok import ngrok, conf\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import tempfile\n",
    "import base64\n",
    "\n",
    "\n",
    "LANGUAGES = {\n",
    "    'python': ['.py'], 'javascript': ['.js', '.jsx'], 'typescript': ['.ts', '.tsx'],\n",
    "    'java': ['.java'], 'c++': ['.cpp', '.hpp'], 'c': ['.c', '.h'],\n",
    "    'c#': ['.cs'], 'go': ['.go'], 'rust': ['.rs'], 'php': ['.php']\n",
    "}\n",
    "\n",
    "def detect_language(filename):\n",
    "    \"\"\"Auto-detect language from file extension\"\"\"\n",
    "    ext = os.path.splitext(filename)[1].lower()\n",
    "    for lang, extensions in LANGUAGES.items():\n",
    "        if ext in extensions:\n",
    "            return lang\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:28:44.864769Z",
     "iopub.status.busy": "2025-11-26T06:28:44.864346Z",
     "iopub.status.idle": "2025-11-26T06:32:00.779709Z",
     "shell.execute_reply": "2025-11-26T06:32:00.778819Z",
     "shell.execute_reply.started": "2025-11-26T06:28:44.864741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713c92ba6a094398875bf262445752a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b66d168502465388a97a0c0b4627bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b254075c744f95b29cb960d9791397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1198e74ee7124117b76aa385ee84fa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 06:28:51.989014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764138532.169661      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764138532.219361      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13b923ace534af9a6e8e7a0ed40926f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197b51c98458419cb27a0cc6a9073870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86689809b7054cb0800713d4a0998fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6364c9d7454b0d943af0c0aa94036c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89e401848b740ac9ccb51578c51d29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bba4564453e4852890f8a4a4e3d3d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160b0a6349e64e2ba5ac5aea4fdac2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a51b8508e404f369956ade603bb2ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce16e2cfc2cb43bd8d00e1b22f3ca0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:32:00.782461Z",
     "iopub.status.busy": "2025-11-26T06:32:00.780839Z",
     "iopub.status.idle": "2025-11-26T06:32:00.789124Z",
     "shell.execute_reply": "2025-11-26T06:32:00.788438Z",
     "shell.execute_reply.started": "2025-11-26T06:32:00.782431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_new_tokens=1200, temperature=0.4, top_p=0.92):\n",
    "    \"\"\"Generate text using the model with better error handling\"\"\"\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        input_length = inputs.input_ids.shape[1]\n",
    "        \n",
    "        # Add attention mask\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        \n",
    "        generated_tokens = outputs[0][input_length:]\n",
    "        response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        \n",
    "        # If response is empty or too short, return a fallback message\n",
    "        if not response or len(response) < 10:\n",
    "            return \"I apologize, but I couldn't generate a proper response. Please try rephrasing your question or ask something more specific about the code.\"\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_text: {str(e)}\")\n",
    "        return f\"Error generating response: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:32:00.790358Z",
     "iopub.status.busy": "2025-11-26T06:32:00.790044Z",
     "iopub.status.idle": "2025-11-26T06:32:00.816282Z",
     "shell.execute_reply": "2025-11-26T06:32:00.815444Z",
     "shell.execute_reply.started": "2025-11-26T06:32:00.790336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chat_with_code(message, code_content, language):\n",
    "    \"\"\"Chat about the uploaded code with improved prompting\"\"\"\n",
    "    if not code_content:\n",
    "        return \"âš ï¸ Please upload a code file first!\"\n",
    "    \n",
    "    # Limit code length to avoid token limits\n",
    "    code_snippet = code_content[:2500] if len(code_content) > 2500 else code_content\n",
    "    \n",
    "    # Better structured prompt\n",
    "    context = f\"\"\"<s>[INST] You are an expert {language} programming assistant. Analyze the following code and answer the user's question clearly and concisely.\n",
    "\n",
    "CODE:\n",
    "```{language}\n",
    "{code_snippet}\n",
    "```\n",
    "\n",
    "QUESTION: {message}\n",
    "\n",
    "Provide a detailed, specific answer about the code. Do not say you cannot see the code or that you need more information. Answer based on what you can see.[/INST]\n",
    "\n",
    "ANSWER: \"\"\"\n",
    "    \n",
    "    # Generate response with retry logic\n",
    "    max_retries = 2\n",
    "    for attempt in range(max_retries):\n",
    "        response = generate_text(context, max_new_tokens=600, temperature=0.5)\n",
    "        \n",
    "        # Check if response is meaningful\n",
    "        if response and len(response.strip()) > 20 and \"couldn't generate\" not in response.lower():\n",
    "            return response\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying...\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return \"I'm having trouble generating a response. Please try asking your question differently or be more specific.\"\n",
    "\n",
    "\n",
    "def create_doc_prompt(code, language):\n",
    "    \"\"\"Create strict prompt that forces structured markdown output\"\"\"\n",
    "    return f\"\"\"You are a technical documentation writer. Generate comprehensive documentation for this code.\n",
    "\n",
    "IMPORTANT: Follow this EXACT structure:\n",
    "\n",
    "# Overview\n",
    "Write 2-3 sentences explaining what this code does and its main purpose.\n",
    "\n",
    "# Dependencies\n",
    "List all imports/libraries and explain what each one is used for:\n",
    "- **Library Name**: What it's used for\n",
    "- **Another Library**: Its purpose\n",
    "\n",
    "# Main Components\n",
    "\n",
    "## Functions\n",
    "\n",
    "For each function, document it like this:\n",
    "\n",
    "### function_name(parameters)\n",
    "- **Purpose**: What this function does\n",
    "- **Parameters**: \n",
    "  - param1 (type): description\n",
    "  - param2 (type): description\n",
    "- **Returns**: What it returns\n",
    "- **Example**:\n",
    "```{language}\n",
    "# Example usage\n",
    "result = function_name(arg1, arg2)\n",
    "```\n",
    "\n",
    "## Classes\n",
    "\n",
    "For each class, document it like this:\n",
    "\n",
    "### ClassName\n",
    "- **Purpose**: What this class does\n",
    "- **Attributes**:\n",
    "  - attribute1: description\n",
    "  - attribute2: description\n",
    "- **Methods**:\n",
    "  - method1(): description\n",
    "  - method2(): description\n",
    "\n",
    "# Usage Example\n",
    "```{language}\n",
    "# Complete working example\n",
    "# Show how to use the main functionality\n",
    "```\n",
    "\n",
    "# Important Notes\n",
    "- List any limitations\n",
    "- Best practices\n",
    "- Common mistakes to avoid\n",
    "\n",
    "NOW DOCUMENT THIS {language.upper()} CODE:\n",
    "\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "Remember: Be specific and detailed. Include actual examples.\"\"\"\n",
    "\n",
    "\n",
    "def create_formatted_doc(documentation, filename, language):\n",
    "    \"\"\"Create professionally formatted Word document\"\"\"\n",
    "    doc = Document()\n",
    "    \n",
    "    # Title page\n",
    "    title = doc.add_heading('Code Documentation', 0)\n",
    "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    subtitle = doc.add_paragraph()\n",
    "    subtitle_run = subtitle.add_run(f'File: {filename}')\n",
    "    subtitle_run.bold = True\n",
    "    subtitle_run.font.size = Pt(14)\n",
    "    subtitle_run.font.color.rgb = RGBColor(128, 128, 128)\n",
    "    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    lang_para = doc.add_paragraph()\n",
    "    lang_run = lang_para.add_run(f'Language: {language.upper()}')\n",
    "    lang_run.font.size = Pt(12)\n",
    "    lang_run.font.color.rgb = RGBColor(0, 102, 204)\n",
    "    lang_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    doc.add_paragraph()\n",
    "    doc.add_page_break()\n",
    "    \n",
    "    # Check if documentation is empty or too short\n",
    "    if not documentation or len(documentation.strip()) < 50:\n",
    "        doc.add_heading('Error', 1)\n",
    "        para = doc.add_paragraph()\n",
    "        para.add_run('Documentation generation failed or produced insufficient content.')\n",
    "        para.add_run('\\n\\nPlease try again or check the code file.')\n",
    "        return doc\n",
    "    \n",
    "    # Parse documentation with proper code block handling\n",
    "    lines = documentation.split('\\n')\n",
    "    in_code_block = False\n",
    "    code_buffer = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check for code block delimiters\n",
    "        if line.strip().startswith('```'):\n",
    "            if in_code_block:\n",
    "                # End of code block - add buffered code\n",
    "                if code_buffer:\n",
    "                    code_text = '\\n'.join(code_buffer)\n",
    "                    para = doc.add_paragraph(code_text)\n",
    "                    para.style = 'Intense Quote'\n",
    "                    if para.runs:\n",
    "                        para.runs[0].font.name = 'Courier New'\n",
    "                        para.runs[0].font.size = Pt(10)\n",
    "                    code_buffer = []\n",
    "                in_code_block = False\n",
    "            else:\n",
    "                # Start of code block\n",
    "                in_code_block = True\n",
    "            continue\n",
    "        \n",
    "        # If inside code block, buffer the line\n",
    "        if in_code_block:\n",
    "            code_buffer.append(line)\n",
    "            continue\n",
    "        \n",
    "        # Process normal lines\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Level 1 Headers\n",
    "        if line.startswith('# ') and not line.startswith('##'):\n",
    "            heading_text = line.replace('# ', '')\n",
    "            heading = doc.add_heading(heading_text, 1)\n",
    "            for run in heading.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 102, 204)\n",
    "        \n",
    "        # Level 2 Headers\n",
    "        elif line.startswith('## ') and not line.startswith('###'):\n",
    "            heading_text = line.replace('## ', '')\n",
    "            heading = doc.add_heading(heading_text, 2)\n",
    "            for run in heading.runs:\n",
    "                run.font.color.rgb = RGBColor(51, 153, 255)\n",
    "                \n",
    "        # Level 3 Headers\n",
    "        elif line.startswith('### '):\n",
    "            heading_text = line.replace('### ', '')\n",
    "            doc.add_heading(heading_text, 3)\n",
    "        \n",
    "        # Bullet points\n",
    "        elif line.startswith('- ') or line.startswith('* '):\n",
    "            content = line[2:]\n",
    "            para = doc.add_paragraph(style='List Bullet')\n",
    "            para.paragraph_format.left_indent = Inches(0.5)\n",
    "            \n",
    "            # Handle bold within bullets\n",
    "            if '**' in content:\n",
    "                parts = content.split('**')\n",
    "                for i, part in enumerate(parts):\n",
    "                    run = para.add_run(part)\n",
    "                    if i % 2 == 1:\n",
    "                        run.bold = True\n",
    "            else:\n",
    "                para.add_run(content)\n",
    "        \n",
    "        # Bold text in paragraphs\n",
    "        elif '**' in line:\n",
    "            para = doc.add_paragraph()\n",
    "            parts = line.split('**')\n",
    "            for i, part in enumerate(parts):\n",
    "                run = para.add_run(part)\n",
    "                if i % 2 == 1:\n",
    "                    run.bold = True\n",
    "        \n",
    "        # Regular text\n",
    "        else:\n",
    "            doc.add_paragraph(line)\n",
    "    \n",
    "    # Footer\n",
    "    doc.add_page_break()\n",
    "    footer_para = doc.add_paragraph()\n",
    "    footer_run = footer_para.add_run('Generated by Code-to-Docs Converter\\nPowered by Mistral AI')\n",
    "    footer_run.font.size = Pt(10)\n",
    "    footer_run.font.color.rgb = RGBColor(128, 128, 128)\n",
    "    footer_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "def generate_documentation(code_content, filename, language):\n",
    "    \"\"\"Generate full documentation with Word file\"\"\"\n",
    "    if not code_content:\n",
    "        return \"âš ï¸ Please upload a code file first!\", None\n",
    "    \n",
    "    try:\n",
    "        print(f\"Starting documentation generation for {filename}...\")\n",
    "        \n",
    "        # Generate documentation text with better prompt\n",
    "        prompt = create_doc_prompt(code_content, language)\n",
    "        print(\"Generating documentation text...\")\n",
    "        docs = generate_text(prompt, max_new_tokens=1500, temperature=0.3)\n",
    "        \n",
    "        print(f\"Documentation generated. Length: {len(docs)} characters\")\n",
    "        print(f\"Preview: {docs[:200]}...\")\n",
    "        \n",
    "        # Create Word document\n",
    "        print(\"Creating Word document...\")\n",
    "        doc = create_formatted_doc(docs, filename, language)\n",
    "        \n",
    "        # Save to temporary file\n",
    "        with tempfile.NamedTemporaryFile(mode='wb', suffix='.docx', delete=False) as tmp_file:\n",
    "            doc.save(tmp_file.name)\n",
    "            word_filename = tmp_file.name\n",
    "        \n",
    "        print(f\"Word document saved: {word_filename}\")\n",
    "        \n",
    "        return docs, word_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate_documentation: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Error generating documentation: {str(e)}\", None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:32:00.817498Z",
     "iopub.status.busy": "2025-11-26T06:32:00.817285Z",
     "iopub.status.idle": "2025-11-26T06:32:00.833116Z",
     "shell.execute_reply": "2025-11-26T06:32:00.832322Z",
     "shell.execute_reply.started": "2025-11-26T06:32:00.817475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NGROK_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # Get from https://dashboard.ngrok.com\n",
    "API_KEY = \"YOUR_SECRET_KEY_HERE\"  # Change this to your own secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:32:00.834462Z",
     "iopub.status.busy": "2025-11-26T06:32:00.834044Z",
     "iopub.status.idle": "2025-11-26T06:32:00.856100Z",
     "shell.execute_reply": "2025-11-26T06:32:00.855355Z",
     "shell.execute_reply.started": "2025-11-26T06:32:00.834438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Setting up FastAPI...\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ Setting up FastAPI...\")\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Code Documentation API\",\n",
    "    description=\"AI-powered code documentation and analysis\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Add CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "def check_auth(request: Request):\n",
    "    \"\"\"Check API key authorization\"\"\"\n",
    "    auth_header = request.headers.get(\"authorization\")\n",
    "    if not auth_header or auth_header != f\"Bearer {API_KEY}\":\n",
    "        raise HTTPException(status_code=401, detail=\"Unauthorized - Invalid API Key\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\n",
    "        \"status\": \"online\",\n",
    "        \"message\": \"Code Documentation API is running\",\n",
    "        \"model\": model_name,\n",
    "        \"endpoints\": [\"/generate\", \"/chat\", \"/documentation\"]\n",
    "    }\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate(req: Request):\n",
    "    \"\"\"Generate text based on prompt - Generic endpoint\"\"\"\n",
    "    check_auth(req)\n",
    "    \n",
    "    try:\n",
    "        data = await req.json()\n",
    "        prompt = data.get(\"prompt\", \"\")\n",
    "        max_length = data.get(\"max_length\", 300)\n",
    "        \n",
    "        if not prompt:\n",
    "            raise HTTPException(status_code=400, detail=\"Prompt is required\")\n",
    "        \n",
    "        response_text = generate_text(prompt, max_new_tokens=max_length)\n",
    "        \n",
    "        return {\n",
    "            \"response\": response_text,\n",
    "            \"prompt_length\": len(prompt),\n",
    "            \"response_length\": len(response_text)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Generation error: {str(e)}\")\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat(req: Request):\n",
    "    \"\"\"Chat about code with validation\"\"\"\n",
    "    check_auth(req)\n",
    "    \n",
    "    try:\n",
    "        data = await req.json()\n",
    "        message = data.get(\"message\", \"\")\n",
    "        code_content = data.get(\"code_content\", \"\")\n",
    "        language = data.get(\"language\", \"python\")\n",
    "        \n",
    "        if not message:\n",
    "            raise HTTPException(status_code=400, detail=\"Message is required\")\n",
    "        if not code_content:\n",
    "            raise HTTPException(status_code=400, detail=\"Code content is required\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Chat request: {message}\")\n",
    "        print(f\"Language: {language}\")\n",
    "        print(f\"Code length: {len(code_content)} characters\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        response = chat_with_code(message, code_content, language)\n",
    "        \n",
    "        # Validate response before sending\n",
    "        if not response or len(response.strip()) < 10:\n",
    "            response = \"I apologize, but I couldn't generate a meaningful response. Please try rephrasing your question.\"\n",
    "        \n",
    "        print(f\"Response generated: {len(response)} characters\")\n",
    "        print(f\"Preview: {response[:100]}...\")\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"message\": message,\n",
    "            \"language\": language\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in chat endpoint: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=f\"Chat error: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Chat error: {str(e)}\")\n",
    "\n",
    "@app.post(\"/documentation\")\n",
    "async def documentation(req: Request):\n",
    "    \"\"\"Generate documentation for code\"\"\"\n",
    "    check_auth(req)\n",
    "    \n",
    "    try:\n",
    "        data = await req.json()\n",
    "        code_content = data.get(\"code_content\", \"\")\n",
    "        filename = data.get(\"filename\", \"code.py\")\n",
    "        language = data.get(\"language\", \"python\")\n",
    "        \n",
    "        if not code_content:\n",
    "            raise HTTPException(status_code=400, detail=\"Code content is required\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Documentation request received:\")\n",
    "        print(f\"Filename: {filename}\")\n",
    "        print(f\"Language: {language}\")\n",
    "        print(f\"Code length: {len(code_content)} characters\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        docs, doc_file = generate_documentation(code_content, filename, language)\n",
    "        \n",
    "        if not doc_file:\n",
    "            raise HTTPException(status_code=500, detail=f\"Failed to generate documentation: {docs}\")\n",
    "        \n",
    "        # Read the file and encode to base64\n",
    "        with open(doc_file, \"rb\") as f:\n",
    "            doc_bytes = f.read()\n",
    "            doc_base64 = base64.b64encode(doc_bytes).decode('utf-8')\n",
    "        \n",
    "        print(f\"Documentation generated successfully!\")\n",
    "        print(f\"Doc length: {len(docs)} characters\")\n",
    "        print(f\"File size: {len(doc_bytes)} bytes\")\n",
    "        \n",
    "        return {\n",
    "            \"documentation\": docs,\n",
    "            \"filename\": os.path.basename(doc_file),\n",
    "            \"file_base64\": doc_base64,\n",
    "            \"language\": language\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise HTTPException(status_code=500, detail=f\"Documentation error: {str(e)}\")\n",
    "\n",
    "@app.post(\"/detect-language\")\n",
    "async def detect_lang(req: Request):\n",
    "    \"\"\"Detect programming language from filename\"\"\"\n",
    "    check_auth(req)\n",
    "    \n",
    "    try:\n",
    "        data = await req.json()\n",
    "        filename = data.get(\"filename\", \"\")\n",
    "        \n",
    "        if not filename:\n",
    "            raise HTTPException(status_code=400, detail=\"Filename is required\")\n",
    "        \n",
    "        language = detect_language(filename)\n",
    "        \n",
    "        return {\n",
    "            \"filename\": filename,\n",
    "            \"language\": language,\n",
    "            \"detected\": language is not None\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Detection error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T06:32:00.857146Z",
     "iopub.status.busy": "2025-11-26T06:32:00.856860Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Starting server with ngrok...\n",
      "                                                                                                    \n",
      "======================================================================\n",
      "ğŸ‰ CODE DOCUMENTATION API IS RUNNING!\n",
      "======================================================================\n",
      "ğŸ“¡ Public URL: https://jacquelyne-veiniest-gilda.ngrok-free.dev\n",
      "ğŸ”‘ API Key: secret123\n",
      "ğŸ”Œ Local Port: 43509\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ COPY THESE TO YOUR STREAMLIT APP:\n",
      "   Ngrok URL: https://jacquelyne-veiniest-gilda.ngrok-free.dev\n",
      "   API Key: secret123\n",
      "======================================================================\n",
      "\n",
      "ğŸ”— Available Endpoints:\n",
      "   GET  https://jacquelyne-veiniest-gilda.ngrok-free.dev/\n",
      "   POST https://jacquelyne-veiniest-gilda.ngrok-free.dev/generate\n",
      "   POST https://jacquelyne-veiniest-gilda.ngrok-free.dev/chat\n",
      "   POST https://jacquelyne-veiniest-gilda.ngrok-free.dev/documentation\n",
      "   POST https://jacquelyne-veiniest-gilda.ngrok-free.dev/detect-language\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ Test your API:\n",
      "   curl 'https://jacquelyne-veiniest-gilda.ngrok-free.dev/'\n",
      "======================================================================\n",
      "\n",
      "â³ Server is running... Keep this cell running!\n",
      "ğŸ›‘ To stop: Interrupt the kernel\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [47]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:43509 (Press CTRL+C to quit)\n",
      "WARNING:pyngrok.process.ngrok:t=2025-11-26T06:32:07+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     41.236.163.240:0 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     41.236.163.240:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     41.236.163.240:0 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "\n",
      "============================================================\n",
      "Chat request: Explain the main purpose\n",
      "Language: python\n",
      "Code length: 1965 characters\n",
      "============================================================\n",
      "\n",
      "Response generated: 1703 characters\n",
      "Preview: The main purpose of this Python script is to create and run a two-player number selection game. Here...\n",
      "INFO:     41.236.163.240:0 - \"POST /chat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸŒ Starting server with ngrok...\")\n",
    "\n",
    "def find_free_port():\n",
    "    \"\"\"Find an available port\"\"\"\n",
    "    s = socket.socket()\n",
    "    s.bind(('', 0))\n",
    "    port = s.getsockname()[1]\n",
    "    s.close()\n",
    "    return port\n",
    "\n",
    "def run_server(port):\n",
    "    \"\"\"Run uvicorn server\"\"\"\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=port, log_level=\"info\")\n",
    "\n",
    "# Configure ngrok\n",
    "port = find_free_port()\n",
    "conf.get_default().auth_token = NGROK_TOKEN\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(port).public_url\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ CODE DOCUMENTATION API IS RUNNING!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ“¡ Public URL: {public_url}\")\n",
    "print(f\"ğŸ”‘ API Key: {API_KEY}\")\n",
    "print(f\"ğŸ”Œ Local Port: {port}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“‹ COPY THESE TO YOUR STREAMLIT APP:\")\n",
    "print(f\"   Ngrok URL: {public_url}\")\n",
    "print(f\"   API Key: {API_KEY}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ”— Available Endpoints:\")\n",
    "print(f\"   GET  {public_url}/\")\n",
    "print(f\"   POST {public_url}/generate\")\n",
    "print(f\"   POST {public_url}/chat\")\n",
    "print(f\"   POST {public_url}/documentation\")\n",
    "print(f\"   POST {public_url}/detect-language\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ’¡ Test your API:\")\n",
    "print(f\"   curl '{public_url}/'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start server in background thread\n",
    "server_thread = threading.Thread(target=run_server, args=(port,), daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Keep the notebook running\n",
    "print(\"\\nâ³ Server is running... Keep this cell running!\")\n",
    "print(\"ğŸ›‘ To stop: Interrupt the kernel\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nğŸ›‘ Server stopped!\")\n",
    "    ngrok.disconnect(public_url)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
